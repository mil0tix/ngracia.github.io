[{"categories":null,"contents":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/basic/introduction/","summary":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","tags":null,"title":"Go পরিচিতি"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/basic/_index.bn/","summary":"","tags":null,"title":"Go বেসিক"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/advanced/_index.bn/","summary":"","tags":null,"title":"অ্যাডভান্সড"},{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/basic/types/","summary":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.","tags":null,"title":"বেসিক টাইপ সমূহ"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.Printf(\u0026#34;At position %d, the character %s is present\\n\u0026#34;, i, val) n := 0 x := 42 for n != x { n := guess() } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/basic/flow-control/","summary":"Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.","tags":null,"title":"Flow Control"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/advanced/files/","summary":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","tags":null,"title":"ফাইল ম্যানিপুলেশন"},{"categories":null,"contents":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/bash/basic/","summary":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","tags":null,"title":"ব্যাশ ভেরিয়েবল"},{"categories":["Basic"],"contents":"Creation of pre-trained autoencoder to learn the initial condensed representation of unlabeled datasets. This architecture consists of 3 parts:\nEncoder: Compresses the input data from the train-validation-test set into a coded representation which is typically smaller by several orders of magnitude than the input data. Latent Space: This space contains the compressed knowledge representations and is thus the most crucial part of the network. Decoder: A module that helps the network to \u0026ldquo;decompress\u0026rdquo; the knowledge representations and reconstruct the data from their coded form. The output is then compared to a ground truth. Imports from time import time import numpy as np import keras.backend as K from keras.layers import Dense, Input, Layer, InputSpec, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose from keras.models import Model from keras.initializers import VarianceScaling from sklearn.cluster import KMeans from sklearn.cluster import MiniBatchKMeans from sklearn import metrics from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt from sklearn.manifold import TSNE from sklearn.decomposition import PCA Loading the data from keras.datasets import mnist from keras.datasets import fashion_mnist import numpy as np # Chargement et normalisation (entre 0 et 1) des données de la base de données MNIST (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.astype(\u0026#39;float32\u0026#39;) / 255. x_test = x_test.astype(\u0026#39;float32\u0026#39;) / 255. x_train = np.reshape(x_train, (len(x_train), 784)) x_test = np.reshape(x_test, (len(x_test), 784)) Classic Autoencoder # Dimension de l\u0026#39;entrée input_img = Input(shape=(784,)) # Dimension de l\u0026#39;espace latent : PARAMETRE A TESTER !! latent_dim = 10 # Définition du encodeur x0 = Dense(500, activation=\u0026#39;relu\u0026#39;)(input_img) x = Dense(200, activation=\u0026#39;relu\u0026#39;)(x0) encoded = Dense(latent_dim, activation=\u0026#39;relu\u0026#39;)(x) # Définition du décodeur decoder_input = Input(shape=(latent_dim,)) x = Dense(200, activation=\u0026#39;relu\u0026#39;)(decoder_input) x1 = Dense(500, activation=\u0026#39;relu\u0026#39;)(x) decoded = Dense(784, activation=\u0026#39;relu\u0026#39;)(x1) # Construction d\u0026#39;un modèle séparé pour pouvoir accéder aux décodeur et encodeur encoder = Model(input_img, encoded) decoder = Model(decoder_input, decoded) # Construction du modèle de l\u0026#39;auto-encodeur encoded = encoder(input_img) decoded = decoder(encoded) autoencoder = Model(input_img, decoded) Summary # Autoencodeur autoencoder.compile(optimizer=\u0026#39;Adam\u0026#39;, loss=\u0026#39;mse\u0026#39;) autoencoder.summary() print(encoder.summary()) print(decoder.summary()) Training autoencoder.fit(x_train, x_train, epochs=20, batch_size=128, shuffle=True, validation_data=(x_test, x_test)) Evaluation # Encode and decode some digits # Note that we take them from the *test* set encoded_imgs = encoder.predict(x_test) decoded_imgs = decoder.predict(encoded_imgs) Visualization n = 10 # How many digits we will display plt.figure(figsize=(20, 4)) for i in range(n): # Display original ax = plt.subplot(2, n, i + 1) plt.imshow(x_test[i].reshape(28, 28)) plt.gray() ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) # Display reconstruction ax = plt.subplot(2, n, i + 1 + n) plt.imshow(decoded_imgs[i].reshape(28, 28)) plt.gray() ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) plt.show() Display # Affichage count=1000 idx = np.random.choice(len(x_test), count) inputs = x_test[idx] coordsAC = encoder.predict(inputs) coordsTSNE = TSNE(n_components=2).fit_transform(inputs.reshape(count, -1)) coordsPCA = PCA(n_components=2).fit_transform(inputs.reshape(count, -1)) classes = y_test[idx] fig, ax = plt.subplots(figsize=(10, 7)) ax.set_title(\u0026#34;Espace latent\u0026#34;) plt.scatter(coordsAC[:, 0], coordsAC[:, 1], c=classes, cmap=\u0026#34;Paired\u0026#34;) plt.colorbar() fig2, ax2 = plt.subplots(figsize=(10, 7)) ax2.set_title(\u0026#34;ACP sur espace latent\u0026#34;) plt.scatter(coordsPCA[:, 0], coordsPCA[:, 1], c=classes, cmap=\u0026#34;Paired\u0026#34;) plt.colorbar() fig3, ax3 = plt.subplots(figsize=(10, 7)) ax3.set_title(\u0026#34;tSNE sur espace latent\u0026#34;) plt.scatter(coordsTSNE[:, 0], coordsTSNE[:, 1], c=classes, cmap=\u0026#34;Paired\u0026#34;) plt.colorbar() ","date":"January 10, 2022","hero":"/posts/ai/machine-learning/autoencoder/images/coded-decoded-mnist.jpg","permalink":"https://noegracia.github.io/posts/ai/machine-learning/autoencoder/","summary":"Creation of pre-trained autoencoder to learn the initial condensed representation of unlabeled datasets. This architecture consists of 3 parts:\nEncoder: Compresses the input data from the train-validation-test set into a coded representation which is typically smaller by several orders of magnitude than the input data. Latent Space: This space contains the compressed knowledge representations and is thus the most crucial part of the network. Decoder: A module that helps the network to \u0026ldquo;decompress\u0026rdquo; the knowledge representations and reconstruct the data from their coded form.","tags":["AI","ML","Autoencoder"],"title":"Autoencoder"},{"categories":["Basic"],"contents":"The objective of this project is to build a Skin Cancer Detection Tool. The tool that we are creating is a segmentation model of spots (moles, melanomas, etc\u0026hellip;) on microscopic images of the skin. To create this tool we will have to train a semantic segmentation AI model. The data that we use for that training is from The International Skin Imaging Collaboration.\nSegmentation model Imports from locale import normalize import tensorflow as tf from tensorflow.keras.layers import * import os import pathlib import cv2 import numpy as np import randomsklearn.metrics import accuracy_score import matplotlib.pyplot as plt from sklearn.manifold import TSNE from sklearn.decomposition import PCA Hyperparameters and reproductibility IMG_WIDTH = 128 IMG_HEIGHT= 128 IMG_CHANNELS = 3 BATCH_SIZE = 16 EPOCHS = 80 SEED = 123 TRAIN_PATH = \u0026#39;train/\u0026#39; TRAIN_LABEL_PATH = \u0026#39;train_labels/\u0026#39; Loading the data def get_data(): print(\u0026#34;Loading data...\u0026#34;) x_train = [] y_train = [] # Load in the images for filepath in os.listdir(TRAIN_PATH): x_img = cv2.imread(TRAIN_PATH+filepath) x_img = cv2.resize(x_img, (IMG_HEIGHT,IMG_WIDTH)) # resize to fit in UNET model # x_img = tf.cast(x_img, tf.float32) / 255.0 # normalize -\u0026gt; return: tensor of floats [0-1] x_train.append(x_img) x_train = np.array(x_train).reshape(-1, IMG_HEIGHT,IMG_WIDTH,3) for filepath in os.listdir(TRAIN_LABEL_PATH): y_img = cv2.imread(TRAIN_LABEL_PATH+filepath,cv2.IMREAD_GRAYSCALE) y_img = cv2.resize(y_img, (IMG_HEIGHT,IMG_WIDTH)) # resize to fit in UNET model # y_img = tf.cast(y_img, tf.float32) / 255.0 # normalize -\u0026gt; return: tensor of floats [0-1] y_img = y_img==255 y_img = np.expand_dims(y_img,axis=-1) y_train.append(y_img) y_train = np.array(y_train).reshape(-1, IMG_HEIGHT,IMG_WIDTH,1) print(\u0026#34;Data loaded!\u0026#34;) return x_train,y_train U-NET IMPLEMENTATION The solution we are going to implement is a U-NET neural network.\ndef build_model(input_size, start_neurons, initializer): print(\u0026#34;Building UNET model\u0026#34;) inputs = Input(input_size) # normalisation de l\u0026#39;input input_layer = Lambda(lambda x: x / 255)(inputs) # encoder conv_1 = Conv2D(start_neurons * 1, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(input_layer) conv_1 = Conv2D(start_neurons * 1, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(conv_1) maxpool_2 = MaxPooling2D(2)(conv_1) maxpool_2 = Dropout(0.2)(maxpool_2) # dropping 20% data to avoid overfitting conv_2 = Conv2D(start_neurons * 2, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(maxpool_2) conv_2 = Conv2D(start_neurons * 2, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(conv_2) maxpool_3 = MaxPooling2D(2)(conv_2) maxpool_3 = Dropout(0.4)(maxpool_3) conv_3 = Conv2D(start_neurons * 4, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(maxpool_3) conv_3 = Conv2D(start_neurons * 4, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(conv_3) maxpool_4 = MaxPooling2D(2)(conv_3) maxpool_4 = Dropout(0.4)(maxpool_4) conv_4 = Conv2D(start_neurons * 8, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(maxpool_4) conv_4 = Conv2D(start_neurons * 8, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(conv_4) # bottom maxpool_bottom = MaxPooling2D(2)(conv_4) maxpool_bottom = Dropout(0.4)(maxpool_bottom) conv_bottom = Conv2D(start_neurons * 16, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(maxpool_bottom) conv_bottom = Conv2D(start_neurons * 16, 3, activation=\u0026#39;relu\u0026#39;, kernel_initializer=initializer, padding=\u0026#39;same\u0026#39;)(conv_bottom) # decoder upconv_4 = Conv2DTranspose(start_neurons * 8, 3, strides=2, padding=\u0026#34;same\u0026#34;)(conv_bottom) merge_4 = concatenate([upconv_4, conv_4]) merge_4 = Dropout(0.5)(merge_4) deconv_4 = Conv2D(start_neurons * 8, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(merge_4) deconv_4 = Conv2D(start_neurons * 8, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(deconv_4) upconv_3 = Conv2DTranspose(start_neurons * 4, 3, strides=2, padding=\u0026#34;same\u0026#34;)(deconv_4) merge_3 = concatenate([upconv_3, conv_3]) merge_3 = Dropout(0.5)(merge_3) deconv_3 = Conv2D(start_neurons * 4, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(merge_3) deconv_3 = Conv2D(start_neurons * 4, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(deconv_3) upconv_2 = Conv2DTranspose(start_neurons * 2, 3, strides=2, padding=\u0026#34;same\u0026#34;)(deconv_3) merge_2 = concatenate([upconv_2, conv_2]) merge_2 = Dropout(0.5)(merge_2) deconv_2 = Conv2D(start_neurons * 2, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(merge_2) deconv_2 = Conv2D(start_neurons * 2, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(deconv_2) upconv_1 = Conv2DTranspose(start_neurons * 1, 3, strides=2, padding=\u0026#34;same\u0026#34;)(deconv_2) merge_1 = concatenate([upconv_1, conv_1]) merge_1 = Dropout(0.5)(merge_1) deconv_1 = Conv2D(start_neurons * 1, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(merge_1) deconv_1 = Conv2D(start_neurons * 1, 3, activation=\u0026#34;relu\u0026#34;, padding=\u0026#34;same\u0026#34;)(deconv_1) output_layer = Conv2D(1, (1,1), padding=\u0026#34;same\u0026#34;, activation=\u0026#34;sigmoid\u0026#34;)(deconv_1) print(input_layer.shape,output_layer.shape) input(\u0026#34;---\u0026#34;) model = tf.keras.Model(inputs = input_layer, outputs = output_layer) print(\u0026#34;UNET built!\u0026#34;) return model Building the model initializer = \u0026#39;he_normal\u0026#39; input_size = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS) model = build_model(input_size, 16, initializer) Compiling the model model.compile(optimizer=\u0026#39;adam\u0026#39;, loss = tf.keras.losses.BinaryCrossentropy(), metrics=[\u0026#39;accuracy\u0026#39;]) # model.summary() Model checkpoint checkpointer = tf.keras.callbacks.ModelCheckpoint(\u0026#39;seg_lesions_cut.h5\u0026#39;, verbose=1, save_best_only=True) file_name = \u0026#39;my_saved_model_80\u0026#39; callbacks = [ checkpointer, tf.keras.callbacks.EarlyStopping(patience=10, monitor=\u0026#39;val_loss\u0026#39;), tf.keras.callbacks.TensorBoard(log_dir=\u0026#39;logs\\\\{}\u0026#39;.format(file_name),) ] Inference Imports import cv2 import tensorflow as tf import numpy as np import os Hyperparameters and reproductibility INPUT_FOLDER = \u0026#39;Input_folder/\u0026#39; OUTPUT_FOLDER = \u0026#39;Output_folder/\u0026#39; IMG_WIDTH = 128 IMG_HEIGHT= 128 IMG_CHANNELS = 3 Load data def get_data(): print(\u0026#34;Loading data...\u0026#34;) x_train = [] # Load in the images for filepath in os.listdir(INPUT_FOLDER): x_img = cv2.imread(INPUT_FOLDER+filepath) x_img = cv2.resize(x_img, (IMG_HEIGHT,IMG_WIDTH)) # resize to fit in UNET model # x_img = tf.cast(x_img, tf.float32) / 255.0 # normalize -\u0026gt; return: tensor of floats [0-1] x_train.append(x_img) x_train = np.array(x_train).reshape(-1, IMG_HEIGHT,IMG_WIDTH,3) print(\u0026#34;Data loaded!\u0026#34;) return x_train Predict model = tf.keras.models.load_model(\u0026#34;segm_model\u0026#34;) prediction = model.predict(get_data()) for i,img in enumerate(prediction): img = cv2.resize(img,(320,240)) img = np.rint(img) cv2.imshow(\u0026#34;test\u0026#34;,img) cv2.waitKey(10000) cv2.destroyAllWindows() cv2.imwrite(OUTPUT_FOLDER+str(i)+\u0026#34;.bmp\u0026#34;,img) ","date":"August 10, 2021","hero":"/posts/ai/machine-learning/segmentation/images/portada-segm.jpg","permalink":"https://noegracia.github.io/posts/ai/machine-learning/segmentation/","summary":"The objective of this project is to build a Skin Cancer Detection Tool. The tool that we are creating is a segmentation model of spots (moles, melanomas, etc\u0026hellip;) on microscopic images of the skin. To create this tool we will have to train a semantic segmentation AI model. The data that we use for that training is from The International Skin Imaging Collaboration.\nSegmentation model Imports from locale import normalize import tensorflow as tf from tensorflow.","tags":["AI","ML","Autoencoder","Personal Project"],"title":"Skin Cancer Detection using semantic segmentation"},{"categories":null,"contents":"Go Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/go/_index.bn/","summary":"Go Notes ","tags":null,"title":"Go এর নোট সমূহ"},{"categories":null,"contents":"Bash Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://noegracia.github.io/notes/bash/_index.bn/","summary":"Bash Notes ","tags":null,"title":"ব্যাশের নোট সমূহ"}]